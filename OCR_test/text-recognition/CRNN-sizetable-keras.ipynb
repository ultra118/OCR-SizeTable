{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAR_VECTOR = \"0123456789d\"\n",
    "# one-hot으로 쓰기위한 letters \n",
    "\n",
    "letters = [letter for letter in CHAR_VECTOR]\n",
    "\n",
    "num_classes = len(letters) + 1\n",
    "\n",
    "img_w, img_h = 48, 56\n",
    "\n",
    "# Network parameters\n",
    "# batch_size = 128\n",
    "# val_batch_size = 16\n",
    "batch_size = 1\n",
    "val_batch_size = 1\n",
    "\n",
    "downsample_factor = 4\n",
    "max_text_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# # Loss and train functions, network architecture\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def get_Model(training):\n",
    "    input_shape = (img_w, img_h, 1)     # (48, 56, 1)\n",
    "\n",
    "    # Make Networkw\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 48, 56, 1)\n",
    "\n",
    "    # Convolution layer (VGG)\n",
    "    inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 48, 56, 32)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None, 24, 56, 32)\n",
    "\n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 24, 56, 64)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
    "\n",
    "    inner = Conv2D(128, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    print(inner)\n",
    "    # CNN to RNN\n",
    "    inner = Reshape(target_shape=((12, 7*128)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "\n",
    "    # RNN layer\n",
    "    lstm_1 = LSTM(128, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
    "    lstm_1b = LSTM(128, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "    lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    \n",
    "    lstm_2 = LSTM(128, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = LSTM(128, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "    lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    lstm_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "    \n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_96/Relu:0\", shape=(?, 12, 7, 128), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 48, 56, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 56, 32)   320         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 48, 56, 32)   128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 48, 56, 32)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 24, 28, 32)   0           activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 24, 28, 64)   18496       max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 24, 28, 64)   256         conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 24, 28, 64)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 12, 14, 64)   0           activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 12, 14, 128)  73856       max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 14, 128)  512         conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 12, 14, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max4 (MaxPooling2D)             (None, 12, 7, 128)   0           activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "con7 (Conv2D)                   (None, 12, 7, 128)   65664       max4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 7, 128)   512         con7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 12, 7, 128)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 12, 896)      0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 12, 64)       57408       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm1_b (LSTM)                  (None, 12, 128)      98816       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm1 (LSTM)                    (None, 12, 128)      98816       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 12, 128)      0           lstm1_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 12, 128)      0           lstm1[0][0]                      \n",
      "                                                                 lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 128)      512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm2_b (LSTM)                  (None, 12, 128)      131584      batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lstm2 (LSTM)                    (None, 12, 128)      131584      batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 12, 128)      0           lstm2_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 12, 256)      0           lstm2[0][0]                      \n",
      "                                                                 lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 12, 14)       3598        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 12, 14)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 682,062\n",
      "Trainable params: 681,102\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_Model(True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "# # Input data generator\n",
    "def labels_to_text(labels):     # letters의 index -> text (string)\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):      # text를 letters 배열에서의 인덱스 값으로 변환\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "\n",
    "class TextImageGenerator:\n",
    "    def __init__(self, img_dirpath, img_w, img_h,\n",
    "                 batch_size, downsample_factor, max_text_len=2):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.img_dirpath = img_dirpath                  # image dir path\n",
    "        self.img_dir = os.listdir(self.img_dirpath)     # images list\n",
    "        self.n = len(self.img_dir)                      # number of images\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts = []\n",
    "\n",
    "    ## samples의 이미지 목록들을 opencv로 읽어 저장하기, texts에는 label 저장\n",
    "    def build_data(self):\n",
    "        print(self.n, \" Image Loading start...\")\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = cv2.imread(self.img_dirpath + img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img.astype(np.float32)\n",
    "            img = (img / 255.0) * 2.0 - 1.0\n",
    "\n",
    "            self.imgs[i, :, :] = img\n",
    "            self.texts.append(img_file[0:-4])\n",
    "        print(len(self.texts) == self.n)\n",
    "        print(self.n, \" Image Loading finish...\")\n",
    "\n",
    "    def next_sample(self):      ## index max -> 0 으로 만들기\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):       ## batch size만큼 가져오기\n",
    "        while True:\n",
    "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])     # (bs, 128, 64, 1)\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])             # (bs, 9)\n",
    "            input_length = np.ones((self.batch_size, 1)) * (self.img_w // self.downsample_factor - 2)  # (bs, 1)\n",
    "            label_length = np.zeros((self.batch_size, 1))           # (bs, 1)\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.T\n",
    "                img = np.expand_dims(img, -1)\n",
    "                X_data[i] = img\n",
    "                Y_data[i] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "                #print(f'Y_data[{i}] : {Y_data[i]}\\ninput_length : {input_length}\\n label_length[{i}]: {label_length[i]}\\n')\n",
    "            \n",
    "            # dict 형태로 복사\n",
    "            inputs = {\n",
    "                'the_input': X_data,  # (bs, 128, 64, 1) --> image\n",
    "                'the_labels': Y_data,  # (bs, 8) --> text를 label로 바꾼 값 (48 17 48 ...)같은\n",
    "                'input_length': input_length,  # (bs, 1) -> 모든 원소 value = 30 --> \n",
    "                'label_length': label_length  # (bs, 1) -> 모든 원소 value = 8 --> label의 길이\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1) -> 모든 원소 0\n",
    "            yield (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_120/Relu:0\", shape=(?, 12, 7, 128), dtype=float32)\n",
      "...New weight data...\n",
      "12  Image Loading start...\n",
      "True\n",
      "12  Image Loading finish...\n",
      "12  Image Loading start...\n",
      "True\n",
      "12  Image Loading finish...\n",
      "Epoch 1/40\n",
      " 9/12 [=====================>........] - ETA: 3s - loss: 19.1104"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'h' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-d2627733764e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[1;31m#callbacks=[checkpoint],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtiger_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                     validation_steps=int(tiger_val.n / val_batch_size))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tmh_env\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m--> 626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-862e7c5994f3>\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mY_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_to_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[0mlabel_length\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m#print(f'Y_data[{i}] : {Y_data[i]}\\ninput_length : {input_length}\\n label_length[{i}]: {label_length[i]}\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-862e7c5994f3>\u001b[0m in \u001b[0;36mtext_to_labels\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtext_to_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m      \u001b[1;31m# text를 letters 배열에서의 인덱스 값으로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mletters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-862e7c5994f3>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtext_to_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m      \u001b[1;31m# text를 letters 배열에서의 인덱스 값으로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mletters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'h' is not in list"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# # Model description and training\n",
    "\n",
    "model = get_Model(training=True)\n",
    "\n",
    "try:\n",
    "    model.load_weights('LSTM+BN4--26--0.011.hdf5')\n",
    "    print(\"...Previous weight data...\")\n",
    "except:\n",
    "    print(\"...New weight data...\")\n",
    "    pass\n",
    "\n",
    "train_file_path = './data/train/'\n",
    "tiger_train = TextImageGenerator(train_file_path, img_w, img_h, batch_size, downsample_factor)\n",
    "tiger_train.build_data()\n",
    "\n",
    "valid_file_path = './data/test/'\n",
    "tiger_val = TextImageGenerator(valid_file_path, img_w, img_h, val_batch_size, downsample_factor)\n",
    "tiger_val.build_data()\n",
    "\n",
    "ada = Adadelta()\n",
    "# loss의 변화량이 0.001보다 적으면 학습의 개선이 없다 판단하고 4 epoch만큼 지속되면 종료\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=4, mode='min', verbose=1)\n",
    "#checkpoint = ModelCheckpoint(filepath='LSTM+BN5--{epoch:02d}--{val_loss:.3f}.hdf5', monitor='loss', verbose=1, mode='min', period=1)\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
    "\n",
    "# generator로 생성된 배치로 학습할떄 fit_generator 사용\n",
    "# \n",
    "model.fit_generator(generator=tiger_train.next_batch(),\n",
    "                    steps_per_epoch=int(tiger_train.n / batch_size),\n",
    "                    epochs=40,\n",
    "                    #callbacks=[checkpoint],\n",
    "                    validation_data=tiger_val.next_batch(),\n",
    "                    validation_steps=int(tiger_val.n / val_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools, os, time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from keras import backend as K\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "Sign = {\"d\": \". \", \"w\": \"~ \", \"h\": \"- \"}\n",
    "\n",
    "\n",
    "\n",
    "def decode_label(out):\n",
    "    # out : (1, 32, 42)\n",
    "    print(f'decode_label.. out.shape : {out.shape}')\n",
    "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index -> len = 32\n",
    "    print(f'decode_label.. out_best : {out_best}')\n",
    "    print(f'decode_label.. out_best.shape : {len(out_best)}')\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "    print(f'decode_label..groupby.. out_best : {out_best}')\n",
    "    outstr = ''\n",
    "    for i in out_best:\n",
    "        if i < len(letters):\n",
    "            outstr += letters[i]\n",
    "    print(f'decode_label..groupby.. outstr : {outstr}')\n",
    "    return outstr\n",
    "\n",
    "\n",
    "# A99th3954같은 형태의 label이 예측되게 되는데 각 label의 위치값으로 번호판 예측\n",
    "def label_to_hangul(label):  # eng -> hangul\n",
    "    region = label[0]\n",
    "    two_num = label[1:3]\n",
    "    hangul = label[3:5]\n",
    "    four_num = label[5:]\n",
    "\n",
    "    try:\n",
    "        region = Sign[region] if region != 'Z' else ''\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        hangul = Hangul[hangul]\n",
    "    except:\n",
    "        pass\n",
    "    return region + two_num + hangul + four_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_116/Relu:0\", shape=(?, 12, 7, 128), dtype=float32)\n",
      "...Previous weight data...\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 0]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 0]\n",
      "decode_label..groupby.. outstr : 0\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 1]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 1]\n",
      "decode_label..groupby.. outstr : 1\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 2]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 2]\n",
      "decode_label..groupby.. outstr : 2\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 9]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 9]\n",
      "decode_label..groupby.. outstr : 9\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 3]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 3]\n",
      "decode_label..groupby.. outstr : 3\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 4]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 4]\n",
      "decode_label..groupby.. outstr : 4\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 5]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 5]\n",
      "decode_label..groupby.. outstr : 5\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 6]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 6]\n",
      "decode_label..groupby.. outstr : 6\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 7]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 7]\n",
      "decode_label..groupby.. outstr : 7\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 8]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 8]\n",
      "decode_label..groupby.. outstr : 8\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 9]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 9]\n",
      "decode_label..groupby.. outstr : 9\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 9]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 9]\n",
      "decode_label..groupby.. outstr : 9\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 12]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 12]\n",
      "decode_label..groupby.. outstr : h\n",
      "***************\n",
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [13, 13, 13, 13, 13, 13, 13, 13, 13, 11]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [13, 11]\n",
      "decode_label..groupby.. outstr : w\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "model = get_Model(training=False)\n",
    "\n",
    "try:\n",
    "    model.load_weights('model.h5')\n",
    "    print(\"...Previous weight data...\")\n",
    "except:\n",
    "    raise Exception(\"No weight file!\")\n",
    "test_dir = './data/train/'\n",
    "test_imgs = os.listdir(test_dir)\n",
    "total = 0\n",
    "acc = 0\n",
    "letter_total = 0\n",
    "letter_acc = 0\n",
    "start = time.time()\n",
    "for test_img in test_imgs:\n",
    "    img = cv2.imread(test_dir + test_img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img_pred = img.astype(np.float32)\n",
    "    img_pred = cv2.resize(img_pred, (48, 56))\n",
    "    img_pred = (img_pred / 255.0) * 2.0 - 1.0\n",
    "    img_pred = img_pred.T\n",
    "    img_pred = np.expand_dims(img_pred, axis=-1)\n",
    "    img_pred = np.expand_dims(img_pred, axis=0)\n",
    "    net_out_value = model.predict(img_pred)\n",
    "    decode_label(net_out_value)\n",
    "    print('***************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode_label.. out.shape : (1, 12, 14)\n",
      "decode_label.. out_best : [10, 10, 5, 5, 5, 5, 5, 10, 10, 10]\n",
      "decode_label.. out_best.shape : 10\n",
      "decode_label..groupby.. out_best : [10, 5, 10]\n",
      "decode_label..groupby.. outstr : d5d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d5d'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_label(net_out_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 64, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_Model(training=False)\n",
    "\n",
    "try:\n",
    "    model.load_weights('model.h5')\n",
    "    print(\"...Previous weight data...\")\n",
    "except:\n",
    "    raise Exception(\"No weight file!\")\n",
    "\n",
    "test_dir = './DB/test/'\n",
    "test_imgs = os.listdir(test_dir)\n",
    "total = 0\n",
    "acc = 0\n",
    "letter_total = 0\n",
    "letter_acc = 0\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for test_img in test_imgs:\n",
    "    img = cv2.imread(test_dir + test_img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    img_pred = img.astype(np.float32)\n",
    "    img_pred = cv2.resize(img_pred, (128, 64))\n",
    "    img_pred = (img_pred / 255.0) * 2.0 - 1.0\n",
    "    img_pred = img_pred.T\n",
    "    img_pred = np.expand_dims(img_pred, axis=-1)\n",
    "    img_pred = np.expand_dims(img_pred, axis=0)\n",
    "    # 1, 128, 64, 1\n",
    "    print(f'img_pred.shape : {img_pred.shape}')\n",
    "\n",
    "    net_out_value = model.predict(img_pred)\n",
    "\n",
    "    pred_texts = decode_label(net_out_value)\n",
    "    print(f'net_out_value.shape : {net_out_value.shape} pred_texts : {pred_texts}')\n",
    "    \n",
    "          \n",
    "    for i in range(min(len(pred_texts), len(test_img[0:-4]))):\n",
    "        if pred_texts[i] == test_img[i]:\n",
    "            letter_acc += 1\n",
    "    letter_total += max(len(pred_texts), len(test_img[0:-4]))\n",
    "\n",
    "    if pred_texts == test_img[0:-4]:\n",
    "        acc += 1\n",
    "    total += 1\n",
    "    print('Predicted: %s  /  True: %s' % (label_to_hangul(pred_texts), label_to_hangul(test_img[0:-4])))\n",
    "\n",
    "end = time.time()\n",
    "total_time = (end - start)\n",
    "print(\"Time : \",total_time / total)\n",
    "print(\"ACC : \", acc / total)\n",
    "print(\"letter ACC : \", letter_acc / letter_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tmh_env] *",
   "language": "python",
   "name": "conda-env-tmh_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
